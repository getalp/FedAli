{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow as tf \n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "import concurrent.futures\n",
    "import hickle as hkl \n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import sklearn.manifold\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from utils import LinearLearningRateScheduler,projectTSNE,load_data,load_checkpoint,get_available_gpus,get_available_cpus,extract_intermediate_model_from_base_model,converTensor,prepareContrastiveData,multi_output_model\n",
    "import argparse\n",
    "import __main__ as main\n",
    "from multiprocessing import get_context,Value,Array,Manager,set_start_method\n",
    "from ctypes import c_char_p  \n",
    "from distutils.util import strtobool\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model \n",
    "import fed_util\n",
    "from sklearn.cluster import KMeans\n",
    "import mae_model\n",
    "import alp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"FEDALI\"\n",
    "# FEDALI, FEDAVG, FEDPROTO\n",
    "# MOON,FEDAVG,FEDALI,FEDPROX\n",
    "\n",
    "dataSetName = 'HHAR'\n",
    "# RealWorld, HHAR\n",
    "\n",
    "input_shape = (128,6)\n",
    "\n",
    "# Show training verbose: 0,1\n",
    "showTrainVerbose = 0\n",
    "\n",
    "# input window size \n",
    "segment_size = 128\n",
    "\n",
    "# input channel count\n",
    "num_input_channels = 6\n",
    "\n",
    "GeneralizationTest = True\n",
    "\n",
    "clientLearningRate =  1e-4\n",
    "\n",
    "batch_fold = 5\n",
    "\n",
    "# model drop out rate\n",
    "dropout_rate = 0.3\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "localEpoch = 1\n",
    "\n",
    "randomSeed = 1\n",
    "\n",
    "communicationRound = 2\n",
    "\n",
    "parallelInstancesCPU = 4\n",
    "\n",
    "parallelInstancesGPU = 2\n",
    "\n",
    "mu = 1.0\n",
    "\n",
    "centerBased = False\n",
    "\n",
    "projection_dim = 192 \n",
    "\n",
    "decayRate = 0.999\n",
    "\n",
    "architecture = \"HART\"\n",
    "\n",
    "prototypeNum = 256\n",
    "\n",
    "loadPretrain = False\n",
    "\n",
    "initial_lr = 0.999\n",
    "end_lr = 0.999\n",
    "influenceFactor = 0.2\n",
    "usePersonalPrototype = False\n",
    "\n",
    "singleUpdate = False\n",
    "\n",
    "useGLU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototypeLayers = [2048,1024,512,256,128,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbOfBlocks = 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(algorithm == \"FEDPROX\"):\n",
    "    mu = 0.2\n",
    "else:\n",
    "    mu = 1.0\n",
    "# MOON,FEDAVG,FEDALI,FEDPROX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive():\n",
    "    return not hasattr(main, '__file__')\n",
    "def add_fit_args(parser):\n",
    "    parser.add_argument('--dataset', type=str, default=dataSetName, \n",
    "        help='Dataset')  \n",
    "    parser.add_argument('--algorithm', type=str, default=algorithm, \n",
    "        help='Algorithm')\n",
    "    parser.add_argument('--mu', type=float, default=mu, \n",
    "        help='Mu')  \n",
    "    parser.add_argument('--centerBased', type=lambda x: bool(strtobool(x)), default=centerBased, \n",
    "        help='centerBased')  \n",
    "    parser.add_argument('--parallelInstancesGPU', type=int, default=parallelInstancesGPU, \n",
    "        help='Number of tasks per GPU')  \n",
    "    parser.add_argument('--localEpoch', type=int, default=localEpoch, \n",
    "        help='Number of tasks per GPU')  \n",
    "    parser.add_argument('--clientLearningRate', type=float, default=clientLearningRate, \n",
    "        help='Number of tasks per GPU')  \n",
    "    parser.add_argument('--influenceFactor', type=float, default=influenceFactor, \n",
    "        help='Number of tasks per GPU')  \n",
    "    parser.add_argument('--initial_lr', type=float, default=initial_lr, \n",
    "        help='Number of tasks per GPU')  \n",
    "    parser.add_argument('--loadPretrain', type=lambda x: bool(strtobool(x)), default=loadPretrain,\n",
    "        help='loadPretrain')  \n",
    "    parser.add_argument('--communicationRound', type=int, default=communicationRound, \n",
    "        help='Number of communicationRound')  \n",
    "    parser.add_argument('--prototypeNum', type=int, default=prototypeNum, \n",
    "        help='Number of prototypeNum')  \n",
    "    parser.add_argument('--usePersonalPrototype', type=lambda x: bool(strtobool(x)), default=usePersonalPrototype,\n",
    "        help='usePersonalPrototype')  \n",
    "    parser.add_argument('--useGLU', type=lambda x: bool(strtobool(x)), default=useGLU,\n",
    "        help='usePersonalPrototype')  \n",
    "    parser.add_argument('--singleUpdate', type=lambda x: bool(strtobool(x)), default=singleUpdate,\n",
    "        help='usePersonalPrototype') \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "if not is_interactive():\n",
    "    args = add_fit_args(argparse.ArgumentParser(description='Federated Learning Experiments'))\n",
    "    dataSetName = args.dataset\n",
    "    algorithm = args.algorithm\n",
    "    localEpoch = args.localEpoch\n",
    "    clientLearningRate = args.clientLearningRate\n",
    "    mu = args.mu\n",
    "    centerBased = args.centerBased\n",
    "    parallelInstancesGPU = args.parallelInstancesGPU\n",
    "    loadPretrain = args.loadPretrain\n",
    "    influenceFactor = args.influenceFactor\n",
    "    communicationRound = args.communicationRound\n",
    "    prototypeNum = args.prototypeNum\n",
    "    usePersonalPrototype = args.usePersonalPrototype\n",
    "    useGLU = args.useGLU\n",
    "    initial_lr = args.initial_lr\n",
    "    singleUpdate = args.singleUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_learningRate_scheduler = LinearLearningRateScheduler(initial_lr,end_lr, communicationRound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototypeNum = prototypeLayers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifierEpoch\n",
    "architectureType = str(algorithm)+'_'+str(architecture)\n",
    "if(communicationRound < 20):\n",
    "    architectureType =  \"Tests/\"+str(architectureType)\n",
    "\n",
    "if(loadPretrain):\n",
    "    architectureType = architectureType +\"_pretrain\"\n",
    "\n",
    "\n",
    "architectureType = architectureType +'_clientLearningRate'+str(clientLearningRate)    \n",
    "\n",
    "if(algorithm == 'FEDALI'):\n",
    "    architectureType = architectureType +'_influenceFactor_'+str(influenceFactor)\n",
    "\n",
    "if(algorithm == 'MOON' or algorithm == 'FEDPROX'):\n",
    "    architectureType = architectureType +\"_mu_\"+str(mu)\n",
    "\n",
    "\n",
    "mainDir = ''\n",
    "folderName = 'results'\n",
    "filepath = mainDir + folderName+'/'+architectureType+'/'+dataSetName+'/'\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "# # # # uncomment for testing\n",
    "# if(os.path.exists(filepath+'checkpoint.hkl')):\n",
    "#     os.remove(filepath+'checkpoint.hkl')\n",
    "# # # # keep on for testing\n",
    "\n",
    "bestModelPath = filepath + 'bestModels/'\n",
    "os.makedirs(bestModelPath, exist_ok=True)\n",
    "\n",
    "trainModelPath = filepath + 'trainModels/'\n",
    "os.makedirs(trainModelPath, exist_ok=True)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "np.random.seed(randomSeed)\n",
    "tf.keras.utils.set_random_seed(randomSeed)\n",
    "tf.random.set_seed(randomSeed)\n",
    "random.seed(randomSeed)\n",
    "checkpointProp = load_checkpoint(filepath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirectory = './Datasets/FL_Clients/'\n",
    "trainDataDirectory = dataDirectory +'trainData/'\n",
    "testDataDirectory = dataDirectory +'testData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "if(dataSetName =='Combined'):\n",
    "    datasetNames = ['HHAR','RealWorld']\n",
    "    \n",
    "    clientDataTrain = []\n",
    "    clientLabelTrain = []\n",
    "    clientDataTest =  []\n",
    "    clientLabelTest = []\n",
    "    datasetClientCounts = []\n",
    "    \n",
    "    for datasetName in datasetNames:\n",
    "        with open(trainDataDirectory + datasetName + '_data.hkl', 'rb') as f:\n",
    "            clientDataTrain.append(hkl.load(f))\n",
    "        with open(trainDataDirectory + datasetName + '_aligned_label.hkl', 'rb') as f:\n",
    "            clientLabelTrain.append(hkl.load(f))\n",
    "        with open(testDataDirectory + datasetName + '_data.hkl', 'rb') as f:\n",
    "            clientDataTest.append(hkl.load(f))\n",
    "        with open(testDataDirectory + datasetName + '_aligned_label.hkl', 'rb') as f:\n",
    "            clientLabelTest.append(hkl.load(f))\n",
    "        datasetClientCounts.append(len(clientLabelTest[-1]))\n",
    "    clientDataTrain = np.hstack((clientDataTrain))\n",
    "    clientLabelTrain = np.hstack((clientLabelTrain))\n",
    "    clientDataTest = np.hstack((clientDataTest))\n",
    "    clientLabelTest = np.hstack((clientLabelTest))\n",
    "    with open(dataDirectory + 'labelNames/Combined.hkl', 'rb') as f:\n",
    "        ACTIVITY_LABEL = hkl.load(f)\n",
    "    activityCount = len(ACTIVITY_LABEL)\n",
    "else:\n",
    "    with open(trainDataDirectory + str(dataSetName) + '_data.hkl', 'rb') as f:\n",
    "        clientDataTrain = hkl.load(f)\n",
    "    with open(trainDataDirectory + str(dataSetName) + '_label.hkl', 'rb') as f:\n",
    "        clientLabelTrain = hkl.load(f)\n",
    "    with open(testDataDirectory + str(dataSetName) + '_data.hkl', 'rb') as f:\n",
    "        clientDataTest = hkl.load(f)\n",
    "    with open(testDataDirectory + str(dataSetName) + '_label.hkl', 'rb') as f:\n",
    "        clientLabelTest = hkl.load(f)\n",
    "    with open(dataDirectory + 'labelNames/' + str(dataSetName) + '.hkl', 'rb') as f:\n",
    "        ACTIVITY_LABEL = hkl.load(f)\n",
    "\n",
    "    activityCount = len(ACTIVITY_LABEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientCount = clientDataTest.shape[0]\n",
    "# to test/develop, you can set clients count manually to a lower number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientCount = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,clientData in enumerate(clientDataTrain):\n",
    "    clientDataTrain[index] = clientData.astype('float32')\n",
    "for index,clientData in enumerate(clientDataTest):\n",
    "    clientDataTest[index] = clientData.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralTrainLabel = np.vstack((clientLabelTrain))\n",
    "centralTestData = np.vstack((clientDataTest))\n",
    "centralTestLabel = np.vstack((clientLabelTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the one here\n",
    "# availableGPUPOOl = get_available_gpus()[:1]\n",
    "availableGPUPOOl = get_available_gpus()\n",
    "\n",
    "resourcePool = availableGPUPOOl \n",
    "if(len(resourcePool) == 0):\n",
    "    resourcePool = availableCPUPOOl * parallelInstancesCPU\n",
    "else:\n",
    "    resourcePool = resourcePool * parallelInstancesGPU\n",
    "    GPUPoolIndex = [client%len(availableGPUPOOl) for client in range(clientCount)]\n",
    "\n",
    "# limits the amount of workers from more than neccesary\n",
    "if(len(resourcePool) > clientCount):\n",
    "    resourcePool = resourcePool[:clientCount]\n",
    "modelPool = np.arange(len(resourcePool)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# client models test againts own test-set\n",
    "trainLossHistory = checkpointProp['trainLossHistory'] \n",
    "trainAccHistory = checkpointProp['trainAccHistory'] \n",
    "testLossHistory = checkpointProp['testLossHistory'] \n",
    "testAccHistory = checkpointProp['testAccHistory']\n",
    "\n",
    "stdTrainLossHistory = checkpointProp['stdTrainLossHistory']\n",
    "stdTrainAccHistory = checkpointProp['stdTrainAccHistory']\n",
    "stdTestLossHistory = checkpointProp['stdTestLossHistory']\n",
    "stdTestAccHistory = checkpointProp['stdTestAccHistory']\n",
    "\n",
    "clientTestLossHistory = checkpointProp['clientTestLossHistory']\n",
    "clientTestAccHistory = checkpointProp['clientTestAccHistory']\n",
    "\n",
    "clientStdTestLossHistory = checkpointProp['clientStdTestLossHistory']\n",
    "clientStdTestAccHistory = checkpointProp['clientStdTestAccHistory']\n",
    "roundTrainingTime = checkpointProp['roundTrainingTime']\n",
    "\n",
    "# server test againts all test-set\n",
    "\n",
    "globalTestLossHistory = checkpointProp['globalTestLossHistory'] \n",
    "globalTestAccHistory = checkpointProp['globalTestAccHistory']\n",
    "\n",
    "\n",
    "globalTestAlignZeroLossHistory = checkpointProp['globalTestAlignZeroLossHistory'] \n",
    "globalTestAlignZeroAccHistory = checkpointProp['globalTestAlignZeroAccHistory']\n",
    "\n",
    "meanHistoryDist = checkpointProp['meanHistoryDist']\n",
    "stdHistoryDist = checkpointProp['stdHistoryDist']\n",
    "\n",
    "meanRoundLayerHistory = checkpointProp['meanRoundLayerHistory']\n",
    "stdRoundLayerHistory = checkpointProp['stdRoundLayerHistory'] \n",
    "\n",
    "meanRoundGeneralLayerHistory = checkpointProp['meanRoundGeneralLayerHistory']\n",
    "stdRoundGeneralLayerHistory = checkpointProp['stdRoundGeneralLayerHistory']\n",
    "\n",
    "bestModelRound = checkpointProp['bestModelRound']\n",
    "currentAccuracy = checkpointProp['currentAccuracy']\n",
    "serverCurrentAccuracy = checkpointProp['serverCurrentAccuracy']\n",
    "serverbestModelRound = checkpointProp['serverbestModelRound']\n",
    "bestServerModelWeights = checkpointProp['bestServerModelWeights']\n",
    "best_local_weights = checkpointProp['best_local_weights']\n",
    "totalEmission = checkpointProp['totalEmission'] \n",
    "currentGeneralizationAccuracy = checkpointProp['currentGeneralizationAccuracy']\n",
    "\n",
    "\n",
    "adaptiveLoss = checkpointProp['adaptiveLoss'] \n",
    "adaptiveLossStd = checkpointProp['adaptiveLossStd'] \n",
    "\n",
    "# prototypeStabilityEpoch = {i: [] for i in range(nbOfBlocks)}\n",
    "# previousPrototype = np.empty(nbOfBlocks, dtype=object)  \n",
    "\n",
    "\n",
    "prototypeStabilityEpoch =  checkpointProp['prototypeStabilityEpoch'] \n",
    "previousPrototype =  checkpointProp['previousPrototype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization for asynchronous client training, client selection\n",
    "roundEnd = []\n",
    "trainPool = range(clientCount)\n",
    "startRound = checkpointProp[\"CommunicationRound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingInit = os.path.exists(filepath+'serverWeights.h5') \n",
    "# if model already ran, we do no load the pre-trained MAE model. We will later load the weights from the previous training instance.\n",
    "\n",
    "if(algorithm == \"FEDALI\"):\n",
    "    pretraindir = './pretrained_models/MAE_ALP_FE.h5'\n",
    "    serverModel = model.createAndLoadHART_ALP(prototypeLayers,\n",
    "                                              activityCount,\n",
    "                                              loadPretrain = loadPretrain, \n",
    "                                              pretrain_dir = pretraindir,\n",
    "                                              useGLU = useGLU,\n",
    "                                              influenceFactor = influenceFactor,\n",
    "                                              singleUpdate = singleUpdate)\n",
    "\n",
    "else:\n",
    "    pretraindir = './pretrained_models/MAE_FE.h5'\n",
    "    serverModel = model.createAndLoadHART(activityCount,\n",
    "                                          loadPretrain = loadPretrain, \n",
    "                                          pretrain_dir = pretraindir)\n",
    "\n",
    "if(trainingInit):\n",
    "    print(\"Weights Found, Loading Server Model Weights\")\n",
    "    serverModel.load_weights(filepath+'serverWeights.h5')\n",
    "else:\n",
    "    serverModel.save_weights(filepath+'serverWeights.h5')\n",
    "\n",
    "# # optmizer is random, because server model will not be used for training, just evaluating\n",
    "serverModel.compile(optimizer=tf.keras.optimizers.SGD(0.005),loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['acc'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPointProgress():\n",
    "    # Initialization of metrics during training\n",
    "    checkpointProp[\"SimCLRFinished\"] = True\n",
    "\n",
    "    checkpointProp[\"CommunicationRound\"] = roundNum + 1\n",
    "\n",
    "    # client models test againts own test-set\n",
    "    checkpointProp['trainLossHistory'] =  trainLossHistory\n",
    "    checkpointProp['trainAccHistory'] =  trainAccHistory\n",
    "    checkpointProp['testLossHistory'] =  testLossHistory\n",
    "    checkpointProp['testAccHistory'] = testAccHistory\n",
    "    checkpointProp['roundTrainingTime'] = roundTrainingTime \n",
    "\n",
    "    checkpointProp['adaptiveLoss'] = adaptiveLoss\n",
    "    checkpointProp['adaptiveLossStd'] = adaptiveLossStd\n",
    "    checkpointProp['stdTestLossHistory'] = stdTestLossHistory\n",
    "    checkpointProp['stdTestAccHistory'] = stdTestAccHistory\n",
    "\n",
    "    # client models test againts all test-set\n",
    "\n",
    "    checkpointProp['clientTestLossHistory'] = clientTestLossHistory\n",
    "    checkpointProp['clientTestAccHistory'] = clientTestAccHistory\n",
    "\n",
    "    checkpointProp['clientStdTestLossHistory'] = clientStdTestLossHistory\n",
    "    checkpointProp['clientStdTestAccHistory'] = clientStdTestAccHistory\n",
    "\n",
    "    # server test againts all test-set\n",
    "\n",
    "    checkpointProp['globalTestLossHistory'] =  globalTestLossHistory\n",
    "    checkpointProp['globalTestAccHistory'] = globalTestAccHistory\n",
    "    \n",
    "    checkpointProp['meanHistoryDist'] = meanHistoryDist\n",
    "    checkpointProp['stdHistoryDist'] = stdHistoryDist\n",
    "\n",
    "    checkpointProp['meanRoundLayerHistory'] = meanRoundLayerHistory\n",
    "    checkpointProp['stdRoundLayerHistory'] =  stdRoundLayerHistory\n",
    "\n",
    "    checkpointProp['meanRoundGeneralLayerHistory'] = meanRoundGeneralLayerHistory\n",
    "    checkpointProp['stdRoundGeneralLayerHistory'] = stdRoundGeneralLayerHistory\n",
    "\n",
    "    checkpointProp['bestModelRound'] = bestModelRound\n",
    "    checkpointProp['currentAccuracy'] = currentAccuracy\n",
    "    checkpointProp['currentGeneralizationAccuracy'] = currentGeneralizationAccuracy\n",
    "\n",
    "    checkpointProp['serverCurrentAccuracy'] = serverCurrentAccuracy\n",
    "    checkpointProp['serverbestModelRound'] = serverbestModelRound\n",
    "    checkpointProp['bestServerModelWeights'] = bestServerModelWeights\n",
    "    checkpointProp['best_local_weights'] = best_local_weights\n",
    "    checkpointProp['totalEmission'] = totalEmission\n",
    "\n",
    "    checkpointProp['prototypeStabilityEpoch'] = prototypeStabilityEpoch\n",
    "    checkpointProp['previousPrototype'] = previousPrototype\n",
    "\n",
    "    checkpointProp['globalTestAlignZeroLossHistory'] = globalTestAlignZeroLossHistory\n",
    "    checkpointProp['globalTestAlignZeroAccHistory'] = globalTestAlignZeroAccHistory\n",
    "#     checkpointProp['autoEncoderHistory'] = autoEncoderHistory.history[\"loss\"]\n",
    "    hkl.dump(checkpointProp, filepath + 'checkpoint.hkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTrainDataSize = np.float32(len(centralTrainLabel))\n",
    "local_coeffs = {}\n",
    "for i in range(0,clientCount):\n",
    "    local_coeffs[i] = np.float32(len(clientLabelTrain[i])) / allTrainDataSize\n",
    "del allTrainDataSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_memory():\n",
    "    \"\"\" Release unused memory resources. Force garbage collection \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enderOutputIndexSearch(model, layerSearchName = \"pooling\"):\n",
    "    representationLayer = 0\n",
    "    for i, layer in enumerate(serverModel.layers):\n",
    "        layer_name = layer.name\n",
    "        if layerSearchName in layer.name:\n",
    "            representationLayer = i\n",
    "            break\n",
    "    if(representationLayer == 0):\n",
    "        raise Exception(\"Unrecognized architecture, Please manually set the 'embedLayerIndex' variable to the layer index of the encoder's output\")\n",
    "    return representationLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedLayerIndex = enderOutputIndexSearch(serverModel,layerSearchName = 'pooling')\n",
    "layerCount = len(serverModel.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "context =  get_context('spawn')\n",
    "\n",
    "if(loadPretrain):\n",
    "    clientsEmbedLayer = embedLayerIndex - 1\n",
    "    # -1 because the input layer doesn't show in model.layer with the pre-trained model declared at the client, but shows on the server\n",
    "else:\n",
    "    clientsEmbedLayer = embedLayerIndex\n",
    "\n",
    "\n",
    "embedLayerIndexTemp = Value('i', clientsEmbedLayer, lock=False)\n",
    "segment_sizeTemp = Value('i', segment_size, lock=False)\n",
    "num_input_channelsTemp = Value('i', num_input_channels, lock=False)\n",
    "activityCountTemp = Value('i', activityCount, lock=False)\n",
    "showTrainVerboseTemp = Value('i', showTrainVerbose, lock=False)\n",
    "clientLearningRateTemp = Value('d', clientLearningRate, lock=False)\n",
    "batch_sizeTemp = Value('i', batch_size, lock=False)\n",
    "localEpochTemp = Value('i', localEpoch, lock=False)\n",
    "centralTestDataTemp = Array('d',centralTestData.flatten(),lock=False)\n",
    "centralTestLabelTemp = Array('d',tf.reshape(centralTestLabel, (-1)),lock=False)\n",
    "generalizationTestTemp = Value('i',True,lock=False)\n",
    "GPULockIndexTemp = Array('i',GPUPoolIndex,lock=False)\n",
    "filepathTemp = manager.Value(c_char_p, filepath,lock=False)\n",
    "muTemp = Value('d', mu, lock=False)\n",
    "client_ids = context.Value('i', -1)\n",
    "\n",
    "\n",
    "shared_vars = (embedLayerIndexTemp,\n",
    "               segment_sizeTemp,\n",
    "               num_input_channelsTemp,\n",
    "               activityCountTemp,\n",
    "               showTrainVerboseTemp,\n",
    "               clientLearningRateTemp,\n",
    "               batch_sizeTemp,\n",
    "               localEpochTemp,\n",
    "               centralTestDataTemp,\n",
    "               centralTestLabelTemp,\n",
    "               generalizationTestTemp,\n",
    "               filepathTemp,\n",
    "               muTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(algorithm == 'FEDALI'):\n",
    "    layerIndexTracker = 0\n",
    "    layerAdaptIndex = []\n",
    "    alignLayerIndex = []\n",
    "    layerSearchName = \"alignment\"\n",
    "    if(loadPretrain):\n",
    "        maeLayerIndex = None\n",
    "        blockSearchName = \"mae_encoder\"\n",
    "        maeEncoderLayerIndex = 0\n",
    "        for i, layer in enumerate(serverModel.layers):\n",
    "            layer_name = layer.name\n",
    "            num_params = len(layer.get_weights())\n",
    "            if blockSearchName in layer.name:\n",
    "                maeLayerIndex = i\n",
    "                maeEncoderLayerIndex = layerIndexTracker\n",
    "                break\n",
    "            layerIndexTracker+= num_params\n",
    "        \n",
    "\n",
    "        # this is very hard coded for HART with the adaptive layer.\n",
    "        layerAdaptIndex = []        \n",
    "        adaptLayerLocation = []\n",
    "        for i, layer in enumerate(serverModel.layers[3].layers):\n",
    "            layer_name = layer.name\n",
    "            num_params = len(layer.get_weights())\n",
    "            if layerSearchName in layer.name:\n",
    "                adaptLayerLocation.append(i)\n",
    "                print(\"Index :\"+str(i))\n",
    "                alignLayerIndex.append(i)\n",
    "                if(useGLU):\n",
    "                    print(layerIndexTracker + 2)\n",
    "                    layerAdaptIndex.append(layerIndexTracker + 2)\n",
    "                else:\n",
    "                    print(layerIndexTracker)\n",
    "                    layerAdaptIndex.append(layerIndexTracker)\n",
    "            layerIndexTracker+= num_params\n",
    "    else:\n",
    "        \n",
    "        adaptLayerLocation = []\n",
    "        for i, layer in enumerate(serverModel.layers):\n",
    "            layer_name = layer.name\n",
    "            num_params = len(layer.get_weights())\n",
    "            print(layer.name)\n",
    "            if layerSearchName in layer.name:\n",
    "                adaptLayerLocation.append(i)\n",
    "                print(\"Index :\"+str(i))\n",
    "                alignLayerIndex.append(i)\n",
    "                if(useGLU):\n",
    "                    print(layerIndexTracker + 2)\n",
    "                    layerAdaptIndex.append(layerIndexTracker + 2)\n",
    "                else:\n",
    "                    print(layerIndexTracker)\n",
    "                    layerAdaptIndex.append(layerIndexTracker)\n",
    "            layerIndexTracker+= num_params\n",
    "    \n",
    "    \n",
    "    adaptLayerLocation = np.repeat(np.expand_dims(adaptLayerLocation, axis=0), clientCount, axis=0)\n",
    "    prototypeLayersDistribute = np.tile(prototypeLayers,(clientCount, 1))\n",
    "    \n",
    "    globalPrototypeIndex = [localIndex+1 for localIndex in layerAdaptIndex]\n",
    "\n",
    "\n",
    "    # can delete this later\n",
    "    localPrototypeDir = filepath + 'clientsLocalPrototypes.hkl'\n",
    "    clientsLocalPrototypes = []\n",
    "    if(os.path.exists(localPrototypeDir)):\n",
    "        clientsLocalPrototypes = hkl.load(localPrototypeDir)\n",
    "        print(\"Local prototypes found, loading them.\")\n",
    "    \n",
    "    else:\n",
    "        for clientIndex in range(clientCount):\n",
    "            clientLocalPrototype = [serverModel.get_weights()[localPrototypeIndex] for localPrototypeIndex in layerAdaptIndex]\n",
    "            clientsLocalPrototypes.append(np.asarray(clientLocalPrototype,dtype=object))\n",
    "        print(\"Local prototypes not found, generating new ones\")\n",
    "        hkl.dump(clientsLocalPrototypes, localPrototypeDir)\n",
    "\n",
    "\n",
    "elif(algorithm == 'MOON'):\n",
    "    prevModelPath = filepath + 'prevModels/'\n",
    "    os.makedirs(prevModelPath, exist_ok=True)\n",
    "\n",
    "    # initalize previous model for first com round\n",
    "    if(not os.path.exists(prevModelPath+'clientModel0.hkl')):\n",
    "        clientPrevModelDir = []\n",
    "        for clientIdx in range(clientCount):\n",
    "            prevClientPath = prevModelPath+'clientModel'+str(clientIdx)+'.h5'\n",
    "            clientPrevModelDir.append(prevClientPath)\n",
    "            serverModel.save_weights(prevClientPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadPretrains = np.tile(loadPretrain,clientCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(algorithm == \"FEDPROTO\"):\n",
    "    os.makedirs(filepath + 'clientModels/', exist_ok=True)\n",
    "    if(os.path.exists(filepath+'globalPrototypes.hkl')):\n",
    "        globalPrototype = hkl.load(filepath+'globalPrototypes.hkl')\n",
    "    else:\n",
    "        globalPrototype = tf.Variable(tf.random.normal((activityCount,projection_dim)),trainable= False)\n",
    "elif(algorithm == \"FEDPER\"):\n",
    "    os.makedirs(filepath + 'clientModels/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning training\n",
    "start_time = time.time()\n",
    "for roundNum in range(startRound,communicationRound):\n",
    "    limit_memory()\n",
    "    roundStartTime = time.time()\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=len(resourcePool),\n",
    "                                            mp_context=context,\n",
    "                                            initializer=fed_util.set_global, \n",
    "                                            initargs=(shared_vars,GPULockIndexTemp,client_ids)\n",
    "                                           ) as executor:\n",
    "        \n",
    "        if(algorithm == 'FEDALI'):\n",
    "            prototypeDecay = np.tile(prototype_learningRate_scheduler(roundNum),(clientCount))\n",
    "            # we do use the global prototype in the 1st communication round\n",
    "            if(roundNum == 0):\n",
    "                influenceFactors = np.tile(0.0,clientCount)\n",
    "            else:    \n",
    "                influenceFactors = np.tile(influenceFactor,clientCount)\n",
    "            usePersonalPrototypes = np.tile(usePersonalPrototype,clientCount)\n",
    "\n",
    "            useGLUs = np.tile(useGLU,clientCount)\n",
    "            singleUpdates = np.tile(singleUpdate,clientCount)\n",
    "            comRoundResults = [x for x in executor.map(fed_util.fedALP_global_Trainer, \n",
    "                               trainPool,\n",
    "                               clientDataTrain, \n",
    "                               clientLabelTrain,\n",
    "                               clientDataTest,\n",
    "                               clientLabelTest,\n",
    "                               prototypeLayersDistribute,\n",
    "                               clientsLocalPrototypes,\n",
    "                               adaptLayerLocation,\n",
    "                               loadPretrains,\n",
    "                               prototypeDecay,\n",
    "                               influenceFactors,\n",
    "                               usePersonalPrototypes,\n",
    "                               useGLUs,\n",
    "                               singleUpdates\n",
    "                              )]\n",
    "        elif(algorithm == 'FEDPROX'):\n",
    "            comRoundResults = [x for x in executor.map(fed_util.fedProx_Trainer, \n",
    "                                   trainPool,\n",
    "                                   clientDataTrain, \n",
    "                                   clientLabelTrain,\n",
    "                                   clientDataTest,\n",
    "                                   clientLabelTest,\n",
    "                                   loadPretrains\n",
    "                                  )]\n",
    "        elif(algorithm == 'MOON'):\n",
    "            comRoundResults = [x for x in executor.map(fed_util.Moon_Trainer, \n",
    "                                   trainPool,\n",
    "                                   clientDataTrain, \n",
    "                                   clientLabelTrain,\n",
    "                                   clientDataTest,\n",
    "                                   clientLabelTest,\n",
    "                                   clientPrevModelDir,\n",
    "                                   loadPretrains\n",
    "                                  )]\n",
    "        elif(algorithm == 'FEDPROTO'):\n",
    "            globalPrototypes = np.tile(globalPrototype,(clientCount,1,1))\n",
    "            comRoundResults = [x for x in executor.map(fed_util.fedProto_Trainer, \n",
    "                                   trainPool,\n",
    "                                   clientDataTrain, \n",
    "                                   clientLabelTrain,\n",
    "                                   clientDataTest,\n",
    "                                   clientLabelTest,\n",
    "                                   globalPrototypes,\n",
    "                                   loadPretrains\n",
    "                                  )]\n",
    "        elif(algorithm == 'FEDPER'):\n",
    "            comRoundResults = [x for x in executor.map(fed_util.fedPer_Trainer, \n",
    "                                   trainPool,\n",
    "                                   clientDataTrain, \n",
    "                                   clientLabelTrain,\n",
    "                                   clientDataTest,\n",
    "                                   clientLabelTest,\n",
    "                                   loadPretrains\n",
    "                                  )]\n",
    "        elif(algorithm == 'FEDAVG'):\n",
    "            comRoundResults = [x for x in executor.map(fed_util.fedAvg_Trainer, \n",
    "                                   trainPool,\n",
    "                                   clientDataTrain, \n",
    "                                   clientLabelTrain,\n",
    "                                   clientDataTest,\n",
    "                                   clientLabelTest,\n",
    "                                   loadPretrains,\n",
    "                                  )]\n",
    "        else:\n",
    "            raise Exception(\"Unrecognized strategy\")\n",
    "\n",
    "    executor.shutdown(wait=True)\n",
    "    gc.collect()\n",
    "        \n",
    "    comRoundResults = np.asarray(comRoundResults, dtype=object)\n",
    "    local_weights = comRoundResults[:,1]\n",
    "    adaptLoss =  comRoundResults[:,2]\n",
    "    trainAcc = comRoundResults[:,3]\n",
    "    trainLoss = comRoundResults[:,4]\n",
    "    testAcc = comRoundResults[:,5]\n",
    "    testLoss = comRoundResults[:,6]\n",
    "    clientTestAcc = comRoundResults[:,7]\n",
    "    clientTestLoss = comRoundResults[:,8]\n",
    "    fitTime = comRoundResults[:,9]\n",
    "    fedProtoAggregate = comRoundResults[:,10]\n",
    "\n",
    "    if(usePersonalPrototype):\n",
    "        clientsLocalPrototypes = []\n",
    "        for clientIndex in range(clientCount):\n",
    "            clientLocalPrototype = [local_weights[clientIndex][localPrototypeIndex] for localPrototypeIndex in layerAdaptIndex]\n",
    "            clientsLocalPrototypes.append(np.asarray(clientLocalPrototype,dtype=object))\n",
    "        hkl.dump(clientsLocalPrototypes,localPrototypeDir)\n",
    "    trainAccHistory.append(np.mean(trainAcc))\n",
    "    stdTrainAccHistory.append(np.std(trainAcc))\n",
    "    trainLossHistory.append(np.mean(trainLoss))\n",
    "    stdTrainLossHistory.append(np.std(trainLoss))\n",
    "    meanTestAcc = np.mean(testAcc)\n",
    "    testAccHistory.append(meanTestAcc)\n",
    "    stdTestAccHistory.append(np.std(testAcc))\n",
    "    meanTestLoss = np.mean(testLoss)\n",
    "    testLossHistory.append(meanTestLoss)\n",
    "    stdTestLossHistory.append(np.std(testLoss))\n",
    "    \n",
    "    if(meanTestAcc > currentAccuracy):\n",
    "        logging.warning(\"Better Personalization Accuracy Observed\")\n",
    "        logging.warning(\"Previous Score: \"+str(currentAccuracy)+\" from round \"+str(bestModelRound)+\", Now:\"+str(meanTestAcc)+\" from round \"+str(roundNum))\n",
    "        best_local_weights = []\n",
    "        for clientID in trainPool:\n",
    "            hkl.dump(local_weights[clientID], bestModelPath + f\"bestModel{clientID}.hkl\")\n",
    "        currentAccuracy = meanTestAcc\n",
    "        bestModelRound = roundNum \n",
    "        gc.collect()\n",
    "\n",
    "    meanGerneralizationAcc = np.mean(clientTestAcc)\n",
    "\n",
    "\n",
    "    clientTestLossHistory.append(np.mean(clientTestLoss))\n",
    "    clientTestAccHistory.append(meanGerneralizationAcc)\n",
    "\n",
    "    clientStdTestLossHistory.append(np.std(clientTestLoss))\n",
    "    clientStdTestAccHistory.append(np.std(clientTestAcc))\n",
    "\n",
    "    if(meanGerneralizationAcc > currentGeneralizationAccuracy):\n",
    "        logging.warning(\"Better Generalization Accuracy Observed\")\n",
    "        logging.warning(\"Previous Score: \"+str(currentGeneralizationAccuracy)+\", Now:\"+str(meanGerneralizationAcc))\n",
    "        currentGeneralizationAccuracy = meanGerneralizationAcc\n",
    "        best_local_weights = []\n",
    "        for clientID in trainPool:\n",
    "            hkl.dump(local_weights[clientID], bestModelPath + f\"bestGenModel{clientID}.hkl\")\n",
    "        currentAccuracy = meanTestAcc\n",
    "        bestModelRound = roundNum \n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    #FedAvg weightedAveraging \n",
    "\n",
    "    newWeight = []\n",
    "    globalPrototypes = []\n",
    "    # localPrototypes = []\n",
    "    if(algorithm == 'FEDALI'):\n",
    "        for index,adaptIndex in enumerate(layerAdaptIndex):\n",
    "            concatClientPrototypes = tf.concat([local_weights[clientIndex][adaptIndex] for clientIndex in range(clientCount)],axis = 0 )\n",
    "            averagedPrototypes = np.sum([local_weights[clientIndex][adaptIndex] * local_coeffs[clientIndex] for clientIndex in range(clientCount)],axis = 0 )\n",
    "            clustering = KMeans(n_clusters=prototypeLayers[index], init=averagedPrototypes, n_init = 1).fit(concatClientPrototypes)\n",
    "            labels = clustering.labels_\n",
    "            unique_cluster = np.unique(labels)\n",
    "            n_clusters = len(unique_cluster)\n",
    "            labels_tensor = tf.constant(labels, dtype=tf.int32)\n",
    "            print(\"Number of cluster: \" +str(n_clusters))                \n",
    "            cluster_means = []\n",
    "            for label in unique_cluster:\n",
    "                cluster_indices = tf.where(tf.equal(labels_tensor, label))  # Find indices of data points in the cluster\n",
    "                cluster_data = tf.gather(concatClientPrototypes, cluster_indices)  # Extract data points in the cluster\n",
    "                cluster_mean = tf.reduce_mean(cluster_data, axis=0)  # Compute the mean of the cluster\n",
    "                cluster_means.append(cluster_mean)\n",
    "            cluster_means_tensor = tf.squeeze(tf.stack(cluster_means)) \n",
    "            globalPrototypes.append(cluster_means_tensor)\n",
    "\n",
    "    \n",
    "    for index,i in enumerate(trainPool):\n",
    "        for j in range(0,len(local_weights[i])):\n",
    "            local_weights[i][j] = local_weights[i][j] * local_coeffs[i]\n",
    "\n",
    "\n",
    "    blockIndex = 0\n",
    "    for layerIndex in range(layerCount):\n",
    "        averagedLayerWeight = np.sum([local_weights[clientIndex][layerIndex] for clientIndex in range(len(local_weights))],axis = 0)\n",
    "        newWeight.append(averagedLayerWeight)\n",
    "\n",
    "        if(algorithm == 'FEDALI' or algorithm == 'FEDPROX_ALP' or algorithm == 'MOON_ALP'):\n",
    "            if(layerIndex in layerAdaptIndex):\n",
    "                if(roundNum != 0):\n",
    "                    prototypeStabilityEpoch[blockIndex].append(tf.reduce_mean(tf.math.abs(globalPrototypes[blockIndex] - previousPrototype[blockIndex])))\n",
    "                previousPrototype[blockIndex] = globalPrototypes[blockIndex]\n",
    "                blockIndex += 1\n",
    "\n",
    "            \n",
    "    if(algorithm == 'FEDALI' or algorithm == 'FEDPROX_ALP' or algorithm == 'MOON_ALP'):\n",
    "        for idx, globalIndex in enumerate(globalPrototypeIndex):\n",
    "            newWeight[globalIndex] = globalPrototypes[idx]\n",
    "        for idx, localIndex in enumerate(layerAdaptIndex):\n",
    "            newWeight[localIndex] = globalPrototypes[idx]\n",
    "            \n",
    "    serverModel.set_weights((newWeight))\n",
    "    del newWeight\n",
    "    del averagedLayerWeight\n",
    "    if(algorithm != 'FEDPER' and algorithm != 'FEDPROTO' ):\n",
    "        logging.warning(\"Evaluating Server Model\")\n",
    "        globalTestMetrics = serverModel.evaluate(centralTestData, centralTestLabel,verbose = showTrainVerbose)\n",
    "        globalTestLossHistory.append(globalTestMetrics[0])\n",
    "        globalTestAccHistory.append(globalTestMetrics[1])\n",
    "        if(globalTestMetrics[1]>serverCurrentAccuracy):\n",
    "            logging.warning(\"Better Global Accuracy Observed\")\n",
    "            logging.warning(\"Previous Score: \"+str(serverCurrentAccuracy)+\" from round \"+str(serverbestModelRound)+\", Now:\"+str(globalTestMetrics[1])+\" from round \"+str(roundNum))\n",
    "            serverCurrentAccuracy = globalTestMetrics[1]\n",
    "            serverbestModelRound = roundNum\n",
    "            serverModel.save_weights(filepath+'bestServerWeights.h5')\n",
    "            bestServerModelWeights = copy.deepcopy(serverModel.get_weights())\n",
    "    serverModel.save_weights(filepath+'serverWeights.h5')\n",
    "    roundEndTime = time.time() - roundStartTime\n",
    "    roundTrainingTime.append(roundEndTime / 60)\n",
    "\n",
    "    if(algorithm == 'FEDPROTO'):\n",
    "\n",
    "        clientActivitySampleCounts = [[len(fedProtoAggregate[clientIdx][activityIdx]) for activityIdx in range(activityCount)] for clientIdx in range(clientCount)]\n",
    "        totalActivitySampleCounts = tf.math.reduce_sum(clientActivitySampleCounts,axis = 0)\n",
    "        \n",
    "        clientLocalPrototypes = []\n",
    "        for clientIdx in range(clientCount):\n",
    "            activityMean = []\n",
    "            for activityIdx in range(activityCount): \n",
    "                clientActivityCoef = tf.cast(clientActivitySampleCounts[clientIdx][activityIdx] / totalActivitySampleCounts[activityIdx],dtype = tf.float32) \n",
    "                if(len(fedProtoAggregate[clientIdx][activityIdx]) > 0 ):\n",
    "                    activityMean.append(tf.math.reduce_mean(fedProtoAggregate[clientIdx][activityIdx], axis = 0) * clientActivityCoef)\n",
    "                else:\n",
    "                    activityMean.append(tf.zeros(projection_dim))\n",
    "            clientLocalPrototypes.append(activityMean)\n",
    "        globalPrototype = tf.reduce_sum(clientLocalPrototypes,axis = 0)\n",
    "\n",
    "        hkl.dump(globalPrototype, filepath + 'globalPrototypes.hkl')\n",
    "    checkPointProgress()\n",
    "    logging.warning(\"Training time on communcation round \" +str(roundNum)+ \" is :\"+str(roundEndTime / 60) +\" minutes\")\n",
    "    logging.warning(\"Fit time \" +str(np.max(fitTime)))\n",
    "    logging.warning(\"Personalization Accuracy \" +str(meanTestAcc) +\" Loss: \" +str(meanTestLoss))\n",
    "    logging.warning(\"Generalization Accuracy \" +str(clientTestAccHistory[-1]) + \" Loss: \" +str(clientTestLossHistory[-1]))\n",
    "    if(algorithm != 'FEDPER' and algorithm != 'FEDPROTO' ):\n",
    "        logging.warning(\"Global Accuracy \" +str(globalTestAccHistory[-1]) +\" Loss: \" +str(globalTestLossHistory[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datatypes to a np formats\n",
    "# std of all clients\n",
    "stdTrainLossHistory = np.asarray(stdTrainLossHistory[:communicationRound])\n",
    "stdTrainAccHistory = np.asarray(stdTrainAccHistory[:communicationRound])\n",
    "stdTestLossHistory = np.asarray(stdTestLossHistory[:communicationRound])\n",
    "stdTestAccHistory = np.asarray(stdTestAccHistory[:communicationRound])\n",
    "\n",
    "clientStdTestLossHistory = np.asarray(clientStdTestLossHistory[:communicationRound])\n",
    "clientStdTestAccHistory = np.asarray(clientStdTestAccHistory[:communicationRound])\n",
    "\n",
    "trainLossHistory = np.asarray(trainLossHistory[:communicationRound])\n",
    "trainAccHistory = np.asarray(trainAccHistory[:communicationRound])\n",
    "testLossHistory = np.asarray(testLossHistory[:communicationRound])\n",
    "testAccHistory = np.asarray(testAccHistory[:communicationRound])\n",
    "\n",
    "clientTestLossHistory = np.asarray(clientTestLossHistory[:communicationRound])\n",
    "clientTestAccHistory = np.asarray(clientTestAccHistory[:communicationRound])\n",
    "\n",
    "if(algorithm != 'FEDPER' and algorithm != 'FEDPROTO' ):\n",
    "    globalTestLossHistory = np.asarray(globalTestLossHistory[:communicationRound])\n",
    "    globalTestAccHistory = np.asarray(globalTestAccHistory[:communicationRound])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the training statistics and results\n",
    "os.makedirs(filepath+'trainingStats', exist_ok=True)\n",
    "\n",
    "hkl.dump(trainLossHistory,filepath + \"trainingStats/trainLossHistory.hkl\" )\n",
    "hkl.dump(trainAccHistory,filepath + \"trainingStats/trainAccHistory.hkl\" )\n",
    "hkl.dump(stdTrainLossHistory,filepath + \"trainingStats/stdTrainLossHistory.hkl\" )\n",
    "hkl.dump(stdTrainAccHistory,filepath + \"trainingStats/stdTrainAccHistory.hkl\" )\n",
    "\n",
    "hkl.dump(testLossHistory,filepath + \"trainingStats/testLossHistory.hkl\" )\n",
    "hkl.dump(testAccHistory,filepath + \"trainingStats/testAccHistory.hkl\" )\n",
    "hkl.dump(stdTestLossHistory,filepath + \"trainingStats/stdTestLossHistory.hkl\" )\n",
    "hkl.dump(stdTestAccHistory,filepath + \"trainingStats/stdTestAccHistory.hkl\" )\n",
    "    \n",
    "if(GeneralizationTest == True):\n",
    "    hkl.dump(clientStdTestLossHistory,filepath + \"trainingStats/clientStdTestLossHistory.hkl\" )\n",
    "    hkl.dump(clientStdTestAccHistory,filepath + \"trainingStats/clientStdTestAccHistory.hkl\" )\n",
    "\n",
    "    hkl.dump(clientTestLossHistory,filepath + \"trainingStats/clientTestLossHistory.hkl\" )\n",
    "    hkl.dump(clientTestAccHistory,filepath + \"trainingStats/clientTestAccHistory.hkl\" )\n",
    "\n",
    "if(algorithm != 'FEDPER' and algorithm != 'FEDPROTO' ):\n",
    "    hkl.dump(globalTestLossHistory,filepath + \"trainingStats/globalTestLossHistory.hkl\" )\n",
    "    hkl.dump(globalTestAccHistory,filepath + \"trainingStats/globalTestAccHistory.hkl\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate line chart function\n",
    "def saveGraph(title = \"\",accuracyOrLoss = \"Accuracy\",asyTest = False,legendLoc = 'lower right'):\n",
    "    plt.title(title)\n",
    "    plt.ylabel(accuracyOrLoss)\n",
    "    plt.xlabel('Communication Round')\n",
    "    plt.legend(loc=legendLoc)\n",
    "    plt.savefig(filepath+title.replace(\" \", \"\")+'.png', bbox_inches=\"tight\", format=\"png\")\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "epoch_range = range(1, communicationRound+1)\n",
    "\n",
    "if(algorithm != 'FEDPER' and algorithm != 'FEDPROTO' ):\n",
    "    plt.plot(epoch_range, globalTestAccHistory, label= 'Global Test',color=\"orange\")\n",
    "    plt.plot(epoch_range, globalTestAccHistory,markevery=[np.argmax(globalTestAccHistory)], ls=\"\", marker=\"o\",color=\"orange\") \n",
    "\n",
    "\n",
    "plt.errorbar(epoch_range, trainAccHistory, yerr=stdTrainAccHistory, label='Personalization Train',alpha=0.6, color= \"green\")\n",
    "plt.errorbar(epoch_range, testAccHistory, yerr=stdTestAccHistory, label='Personalization Test',alpha=0.6, color='red')\n",
    "\n",
    "plt.plot(epoch_range, trainAccHistory,markevery=[np.argmax(trainAccHistory)], ls=\"\", marker=\"o\",color=\"green\")\n",
    "plt.plot(epoch_range, testAccHistory,markevery=[np.argmax(testAccHistory)], ls=\"\", marker=\"o\",color=\"red\")  \n",
    "\n",
    "if(GeneralizationTest == True):\n",
    "    plt.errorbar(epoch_range, clientTestAccHistory, yerr=clientStdTestAccHistory, label='Generalization Test',alpha=0.6, color=\"brown\")\n",
    "    plt.plot(epoch_range, clientTestAccHistory,markevery=[np.argmax(clientTestAccHistory)], ls=\"\", marker=\"o\",color=\"brown\")  \n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Communication Round')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(filepath+'LearningAccuracy.png', bbox_inches=\"tight\", format=\"png\")\n",
    "plt.clf()\n",
    "\n",
    "if(algorithm != 'FEDPER' and algorithm != 'FEDPROTO' ):\n",
    "    plt.plot(epoch_range, globalTestLossHistory, label= 'Global Test',color=\"orange\")\n",
    "    plt.plot(epoch_range, globalTestLossHistory,markevery=[np.argmin(globalTestLossHistory)], ls=\"\", marker=\"o\",color=\"orange\") \n",
    "    \n",
    "plt.errorbar(epoch_range, trainLossHistory, yerr=stdTrainLossHistory, label='Personalization Train',alpha=0.6, color='green')\n",
    "plt.errorbar(epoch_range, testLossHistory, yerr=stdTestLossHistory, label='Personalization Test',alpha=0.6, color='red')\n",
    "plt.plot(epoch_range, trainLossHistory,markevery=[np.argmin(trainLossHistory)], ls=\"\", marker=\"o\",color=\"green\")\n",
    "plt.plot(epoch_range, testLossHistory,markevery=[np.argmin(testLossHistory)], ls=\"\", marker=\"o\",color=\"red\")  \n",
    "\n",
    "if(GeneralizationTest == True):\n",
    "    plt.errorbar(epoch_range, clientTestLossHistory, yerr=clientStdTestLossHistory, label='Generalization Test',alpha=0.6,color=\"brown\")\n",
    "    plt.plot(epoch_range, clientTestLossHistory,markevery=[np.argmin(clientTestLossHistory)], ls=\"\", marker=\"o\",color=\"brown\")  \n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Communication Round')\n",
    "plt.legend(loc= 'upper right')\n",
    "plt.savefig(filepath+'LearningLoss.png', bbox_inches=\"tight\", format=\"png\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding number function \n",
    "def roundNumber(toRoundNb):\n",
    "    return round(np.mean(toRoundNb), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating personalized accuracy\n",
    "indiWeightedTest = []\n",
    "indiMicroTest = []\n",
    "indiMacroTest = []\n",
    "\n",
    "genWeightedTest = []\n",
    "genMicroTest = []\n",
    "genMacroTest = []\n",
    "\n",
    "genBestMacroTest = []\n",
    "\n",
    "os.makedirs(filepath+'models/' , exist_ok=True)\n",
    "\n",
    "for i in trainPool:\n",
    "    print(\"Loading Client \"+str(i))\n",
    "\n",
    "    best_weights = hkl.load(bestModelPath + f\"bestModel{i}.hkl\")\n",
    "    serverModel.set_weights(best_weights)\n",
    "    y_pred = np.argmax(serverModel.predict(clientDataTest[i],verbose = showTrainVerbose), axis=-1)\n",
    "    y_test = np.argmax(clientLabelTest[i], axis=-1)\n",
    "\n",
    "    indiWeightedTest.append(f1_score(y_test, y_pred,average='weighted' ))\n",
    "    indiMicroTest.append(f1_score(y_test, y_pred,average='micro' ))\n",
    "    indiMacroTest.append(f1_score(y_test, y_pred,average='macro' ))\n",
    "\n",
    "    y_pred = np.argmax(serverModel.predict(centralTestData,verbose = showTrainVerbose), axis=-1)\n",
    "    y_test = np.argmax(centralTestLabel, axis=-1)    \n",
    "\n",
    "    genWeightedTest.append(f1_score(y_test, y_pred,average='weighted'))\n",
    "    genMicroTest.append(f1_score(y_test, y_pred,average='micro'))\n",
    "    genMacroTest.append(f1_score(y_test, y_pred,average='macro'))\n",
    "    del best_weights\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "modelStatistics = {\n",
    "    \"Personalization Accuracy:\" : '',\n",
    "    \"\\nBestModelRound:\": bestModelRound,\n",
    "    \"\\nweighted f1:\" : roundNumber(np.mean(indiWeightedTest)) * 100,\n",
    "    \"\\nmicro f1:\": roundNumber(np.mean(indiMicroTest)) * 100,\n",
    "    \"\\nmacro f1:\": roundNumber(np.mean(indiMacroTest)) * 100,\n",
    "    \"\\nmacro std f1:\": roundNumber(np.std(indiMacroTest)) * 100,\n",
    "    \"\\nround mean time:\": np.mean(roundTrainingTime),\n",
    "    \"\\nround std time:\": np.std(roundTrainingTime),\n",
    "}    \n",
    "with open(filepath +'PersonalizationACC.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(modelStatistics.items())\n",
    "\n",
    "\n",
    "for i in trainPool:\n",
    "    print(\"Loading Client \"+str(i))\n",
    "\n",
    "\n",
    "    best_gen_weights = hkl.load(bestModelPath + f\"bestGenModel{i}.hkl\")\n",
    "\n",
    "    serverModel.set_weights(best_gen_weights)\n",
    "    \n",
    "    y_pred = np.argmax(serverModel.predict(centralTestData,verbose = showTrainVerbose), axis=-1)\n",
    "    y_test = np.argmax(centralTestLabel, axis=-1)    \n",
    "    genBestMacroTest.append(f1_score(y_test, y_pred,average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "modelStatistics = {\n",
    "\"Generalization Accuracy:\" : '',\n",
    "\"\\Generalization Best Model Round:\": bestModelRound,\n",
    "\"\\nGeneralization weighted f1:\" : roundNumber(np.mean(genWeightedTest)) * 100,\n",
    "\"\\nGeneralization micro f1:\": roundNumber(np.mean(genMicroTest)) * 100,\n",
    "\"\\nGeneralization macro f1:\": roundNumber(np.mean(genMacroTest)) * 100,\n",
    "\"\\nGeneralization macro std f1:\": roundNumber(np.std(genMacroTest)) * 100,\n",
    "\"\\nGeneralization macro std f1:\": roundNumber(np.std(genMacroTest)) * 100,\n",
    "\"\\nGeneralization best macro f1:\": roundNumber(np.mean(genBestMacroTest)) * 100,\n",
    "\n",
    "}    \n",
    "with open(filepath +'GeneralizationACC.csv','w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(modelStatistics.items())\n",
    "\n",
    "hkl.dump(indiMacroTest,filepath + 'indiMacroTest.hkl') \n",
    "hkl.dump(genMacroTest,filepath + 'genMacroTest.hkl') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_intermediate_model_from_base_model(base_model, intermediate_layer=4):\n",
    "    model = tf.keras.Model(inputs=base_model.inputs, outputs=base_model.layers[intermediate_layer].output, name=base_model.name + \"_layer_\" + str(intermediate_layer))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientOneIndex = 0\n",
    "clientTwoIndex = 1\n",
    "\n",
    "if(dataSetName == 'Combined'):\n",
    "    clientOneIndex = 0\n",
    "    clientTwoIndex = datasetClientCounts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and set weights for clientOneIndex\n",
    "best_weights_client_one = hkl.load(bestModelPath + f\"bestModel{clientOneIndex}.hkl\")\n",
    "\n",
    "serverModel.set_weights(best_weights_client_one)\n",
    "embed1 = extract_intermediate_model_from_base_model(serverModel, embedLayerIndex)(clientDataTest[clientOneIndex])\n",
    "\n",
    "# Load and set weights for clientTwoIndex\n",
    "best_weights_client_two = hkl.load(bestModelPath + f\"bestModel{clientTwoIndex}.hkl\")\n",
    "serverModel.set_weights(best_weights_client_two)\n",
    "embed2 = extract_intermediate_model_from_base_model(serverModel, embedLayerIndex)(clientDataTest[clientTwoIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perplexity = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientEmbeddingFilePath = filepath + \"clientEmbeddings/\"\n",
    "os.makedirs(clientEmbeddingFilePath, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(algorithm != 'FEDPER' and algorithm != 'FEDPROTO' ):\n",
    "    serverModel.set_weights(bestServerModelWeights)\n",
    "    y_pred = np.argmax(serverModel.predict(centralTestData,verbose = showTrainVerbose), axis=-1)\n",
    "    y_test = np.argmax(centralTestLabel, axis=-1)    \n",
    "    \n",
    "    weightVal_f1 = f1_score(y_test, y_pred,average='weighted' )\n",
    "    microVal_f1 = f1_score(y_test, y_pred,average='micro')\n",
    "    macroVal_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "    \n",
    "    modelStatistics = {\n",
    "    \"Global Accuracy\" : '',\n",
    "    \"\\nServer Best Model Round\": serverbestModelRound,\n",
    "    \"\\nGlobal Accuracy:\" : roundNumber(serverCurrentAccuracy) * 100,\n",
    "    \"\\nGlobal weighted f1:\" : roundNumber(weightVal_f1) * 100,\n",
    "    \"\\nGlobal micro f1:\": roundNumber(microVal_f1) * 100,\n",
    "    \"\\nGlobal macro f1:\": roundNumber(macroVal_f1) * 100,\n",
    "    }    \n",
    "    with open(filepath +'GlobalACC.csv','w') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerows(modelStatistics.items())\n",
    "    hkl.dump(macroVal_f1,filepath + 'macroVal_f1.hkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_argmax = np.argmax(np.vstack((clientLabelTest[clientOneIndex],clientLabelTest[clientTwoIndex])), axis=-1)\n",
    "unique_labels = np.unique(labels_argmax)\n",
    "clientIndex = np.hstack((np.full(len(clientLabelTest[clientOneIndex]),0),np.full(len(clientLabelTest[clientTwoIndex]),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(algorithm == \"FEDALI\"):\n",
    "    memoryStabilityPath = filepath+\"protoTypeImages/\"\n",
    "    os.makedirs(memoryStabilityPath, exist_ok=True)\n",
    "    prototypeStabilityCR = [prototypeStabilityEpoch[key] for key in prototypeStabilityEpoch]\n",
    "    for index, layerMemoryStability in enumerate(prototypeStabilityCR):\n",
    "        epoch_range = range(1, communicationRound)\n",
    "        plt.plot(epoch_range, layerMemoryStability)\n",
    "        plt.title('Prototype Displacements For Block '+str(index))\n",
    "        plt.ylabel('L1 Distance')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.savefig(memoryStabilityPath+\"B_\"+str(index+1)+\"_memoryDisplacement.png\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "    epoch_range = range(1, communicationRound)\n",
    "    meanMemory = np.mean(prototypeStabilityCR,axis = 0)\n",
    "    stdMemory = np.std(prototypeStabilityCR,axis = 0)\n",
    "    plt.errorbar(epoch_range, meanMemory, yerr=stdMemory)\n",
    "    plt.title('Mean Prototype Displacements')\n",
    "    plt.ylabel('L1 Distance')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.savefig(memoryStabilityPath+\"meanMemoryDisplacement.png\", bbox_inches=\"tight\")\n",
    "    # plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne_model = sklearn.manifold.TSNE(perplexity=perplexity, verbose=showTrainVerbose, random_state=randomSeed)\n",
    "tsne_projections = tsne_model.fit_transform(np.vstack((embed1,embed2)))\n",
    "pandaData = {'col1': tsne_projections[:,0], 'col2': tsne_projections[:,1],'Classes':labels_argmax,'Client':clientIndex}\n",
    "pandaDataFrame = pd.DataFrame(data=pandaData)\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.title('Embeddings Between 2 Clients')\n",
    "graph = sns.scatterplot(data=pandaDataFrame, x=\"col1\", y=\"col2\", hue=\"Classes\", style=\"Client\",\n",
    "                palette=sns.color_palette(n_colors = len(unique_labels)),\n",
    "                s=100, alpha=1.0,rasterized=True,)\n",
    "plt.tick_params(\n",
    "axis='both',         \n",
    "which='both',     \n",
    "bottom=False,     \n",
    "top=False,         \n",
    "labelleft=False,        \n",
    "labelbottom=False)\n",
    "ax = plt.gca()\n",
    "ax.axes.xaxis.set_visible(False)\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "legend = graph.legend_\n",
    "for i in range(len(ACTIVITY_LABEL)):\n",
    "    legend.get_texts()[i+1].set_text(ACTIVITY_LABEL[i]) \n",
    "plt.savefig(filepath+'Overlap_Embeddings.png', dpi=200,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "hkl.dump(tsne_projections,filepath + \"overlappingRepresentations.hkl\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"Training Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
