{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on googlecolab \n",
    "# !pip install hickle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/PerCom2021-FL-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl \n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "randomSeed = 0\n",
    "np.random.seed(randomSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDir = './Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetList = ['HHAR','RealWorld'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName =  mainDir + '/FL_Clients'\n",
    "os.makedirs(dirName, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTuneDir = 'trainData'\n",
    "testDir = 'testData'\n",
    "datasetDir = 'datasets'\n",
    "# os.makedirs(dirName+'/'+datasetDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+fineTuneDir, exist_ok=True)\n",
    "os.makedirs(dirName+'/'+testDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHAR_Activities = ['Sitting', 'Standing', 'Walking', 'Upstair', 'Downstair', 'Biking']\n",
    "RW_Activities = ['Downstair','Upstair','Running','Sitting','Standing','Walking','Lying','Jumping']\n",
    "AlignedLabels = ['Sitting', 'Standing', 'Walking', 'Upstair', 'Downstair', 'Biking','Running','Lying','Jumping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RWMapping = [4,3,6,0,1,2,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datasetIndex,dataSetName in enumerate(datasetList):\n",
    "    datasetLabel = hkl.load(mainDir + '/processedDatasets/'+dataSetName+'/clientsLabel.hkl')\n",
    "    datasetTrain = hkl.load(mainDir + '/processedDatasets/'+dataSetName+'/clientsData.hkl')\n",
    "    \n",
    "    trainingData = []\n",
    "    testingData = []\n",
    "    trainingLabel = []\n",
    "    testingLabel = []\n",
    "    \n",
    "    alignedTrainingLabel = []\n",
    "    alignedTestingLabel = []\n",
    "    \n",
    "    for datasetData, datasetLabels in zip(datasetTrain,datasetLabel):        \n",
    "        skf = StratifiedKFold(n_splits=10,shuffle = False)\n",
    "        skf.get_n_splits(datasetData, datasetLabels)\n",
    "        testIndex = []\n",
    "        \n",
    "        for train_index, test_index in skf.split(datasetData, datasetLabels):\n",
    "            testIndex.append(test_index)\n",
    "\n",
    "        trainIndex = np.hstack((testIndex[:7]))\n",
    "        testIndex = np.hstack((testIndex[7:]))\n",
    "\n",
    "        X_train = tf.gather(datasetData,trainIndex).numpy()\n",
    "        X_test = tf.gather(datasetData,testIndex).numpy()\n",
    "        \n",
    "        y_train = tf.gather(datasetLabels,trainIndex).numpy()\n",
    "        y_test = tf.gather(datasetLabels,testIndex).numpy()\n",
    "\n",
    "        if(dataSetName == 'RealWorld'):\n",
    "\n",
    "            y_train_onehot = tf.one_hot(y_train,len(RW_Activities))\n",
    "            y_test_onehot = tf.one_hot(y_test,len(RW_Activities))\n",
    "\n",
    "            alignedLabel = np.asarray([RWMapping[labelIndex] for labelIndex in datasetLabels])\n",
    "            \n",
    "            y_train_aligned = tf.gather(alignedLabel,trainIndex).numpy()\n",
    "            y_test_aligned = tf.gather(alignedLabel,testIndex).numpy()\n",
    "            \n",
    "            y_train_aligned_onehot = tf.one_hot(y_train_aligned,len(AlignedLabels))\n",
    "            y_test_aligned_onehot = tf.one_hot(y_test_aligned,len(AlignedLabels))\n",
    "            \n",
    "\n",
    "        else:\n",
    "            y_train_onehot = tf.one_hot(y_train,len(HHAR_Activities))\n",
    "            y_test_onehot = tf.one_hot(y_test,len(HHAR_Activities))\n",
    "\n",
    "            y_train_aligned_onehot = tf.one_hot(y_train,len(AlignedLabels))\n",
    "            y_test_aligned_onehot = tf.one_hot(y_test,len(AlignedLabels))\n",
    "            \n",
    "        trainingData.append(X_train)\n",
    "        testingData.append(X_test)\n",
    "        \n",
    "        trainingLabel.append(y_train_onehot)\n",
    "        testingLabel.append(y_test_onehot)\n",
    "\n",
    "\n",
    "        alignedTrainingLabel.append(y_train_aligned_onehot)\n",
    "        alignedTestingLabel.append(y_test_aligned_onehot)\n",
    "\n",
    "    trainingData = np.asarray(trainingData, dtype=object)\n",
    "    trainingLabel = np.asarray(trainingLabel, dtype=object)\n",
    "    alignedTrainingLabel = np.asarray(alignedTrainingLabel, dtype=object)\n",
    "\n",
    "    testingData = np.asarray(testingData, dtype=object)\n",
    "    testingLabel = np.asarray(testingLabel, dtype=object)\n",
    "    alignedTestingLabel = np.asarray(alignedTestingLabel, dtype=object)\n",
    "\n",
    "    \n",
    "    hkl.dump(trainingData,dirName+'/'+fineTuneDir+ '/'+dataSetName+'_data.hkl')\n",
    "    hkl.dump(trainingLabel,dirName+'/'+fineTuneDir+ '/'+dataSetName+'_label.hkl')\n",
    "    hkl.dump(alignedTrainingLabel,dirName+'/'+fineTuneDir+ '/'+dataSetName+'_aligned_label.hkl')\n",
    "\n",
    "    \n",
    "    hkl.dump(testingData,dirName+'/'+testDir+ '/'+dataSetName+'_data.hkl' )\n",
    "    hkl.dump(testingLabel,dirName+'/'+testDir+ '/'+dataSetName+'_label.hkl' )\n",
    "    hkl.dump(alignedTestingLabel,dirName+'/'+testDir+ '/'+dataSetName+'_aligned_label.hkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirLabels =  mainDir + '/FL_Clients/labelNames'\n",
    "os.makedirs(dirLabels, exist_ok=True)\n",
    "hkl.dump(HHAR_Activities,dirLabels+'/HHAR.hkl')\n",
    "hkl.dump(RW_Activities,dirLabels+'/RealWorld.hkl')\n",
    "hkl.dump(AlignedLabels,dirLabels+'/Combined.hkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
